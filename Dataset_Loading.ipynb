{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/sccn/sound2meg/blob/main/Dataset_Loading.ipynb",
      "authorship_tag": "ABX9TyNTpBNuVaAnhRIHcEougj0O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sccn/sound2meg/blob/main/Dataset_Loading.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from os import listdir\n",
        "from scipy.io import loadmat\n",
        "filename = []\n",
        "for mat_file in listdir('/content/drive/MyDrive/sound2meg/mat_files'):\n",
        "  filename.append(mat_file)\n",
        "sizes = []\n",
        "for file in filename:\n",
        "  mat_file = loadmat('/content/drive/MyDrive/sound2meg/mat_files/' + file)  #Was really slow to import every file to check the size, hence not included in the class\n",
        "  Signal = mat_file['data']\n",
        "  sizes.append(Signal.shape[2])"
      ],
      "metadata": {
        "id": "o-uGeSfF4ak0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.io import savemat\n",
        "file_sizes = {'file_sizes': sizes}\n",
        "savemat('file_sizes.mat', file_sizes)"
      ],
      "metadata": {
        "id": "h1IkA3EiiM-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(loadmat('/content/drive/MyDrive/file_sizes.mat')['file_sizes'][0])"
      ],
      "metadata": {
        "id": "lJt7Pvuriyl-",
        "outputId": "bc5eff29-58f7-466f-dc26-ef31e470f754",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([147, 168, 171, 166, 167, 178, 170, 152, 180,  99, 165, 169, 170,\n",
              "       169, 170, 171, 164, 174, 160, 174, 183, 171, 178, 162, 155, 167,\n",
              "       163, 154, 164,  90, 174, 168, 162, 173, 163, 170, 170, 169, 170,\n",
              "       178, 174, 170, 163, 162, 164, 170, 179, 164, 178, 146, 177, 170,\n",
              "       160, 169, 178, 153, 166, 172, 158, 167, 164, 105, 174, 169, 169,\n",
              "       166,  49, 172, 168, 164, 166, 166, 165, 177, 161, 166, 169, 168,\n",
              "       178, 165, 168, 160, 171, 171, 169, 165, 173, 157, 170, 171, 157,\n",
              "       171, 171, 172, 156, 175, 158, 168, 168, 164])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "4zzo_rM4Dotk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from scipy.io import loadmat\n",
        "from os import listdir\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "import random\n",
        "\n",
        "class Sound2MEGDataset(Dataset):\n",
        "  def __init__(self, meg_files_path):\n",
        "    #self.wav_files = wav_files\n",
        "    self.meg_files_path = meg_files_path\n",
        "    self.sizes = np.array(loadmat('/content/drive/MyDrive/file_sizes.mat')['file_sizes'][0])\n",
        "    self.filename = []\n",
        "    for mat_file in listdir(self.meg_files_path):\n",
        "      self.filename.append(mat_file)\n",
        "  def __len__(self):\n",
        "    return sum(self.sizes)\n",
        "  def __getitem__(self, idx):\n",
        "    for i in range(len(self.sizes)):\n",
        "      if np.cumsum(self.sizes)[i] > idx:\n",
        "        idx_file = i\n",
        "        break\n",
        "    mat_file = loadmat(self.meg_files_path + self.filename[idx_file])\n",
        "    if idx_file == 0:\n",
        "      idx_sound = idx\n",
        "    else:\n",
        "      idx_sound = idx - np.cumsum(self.sizes)[idx_file - 1]\n",
        "    audio_file = mat_file['audiofiles'][0, idx_sound][0][0:3]\n",
        "    Sound_Signal = np.load('/content/drive/MyDrive/Mel_Embedding/mel_' + audio_file + '.npy')\n",
        "    mat_file = mat_file['data']\n",
        "    MEG_Signal = np.float32(mat_file[:273, :, idx_sound])\n",
        "    mean_5 = np.mean(MEG_Signal[:,:60], axis=1)\n",
        "    MEG_Signal = MEG_Signal - mean_5[:,None]\n",
        "    scaler = RobustScaler().fit(MEG_Signal)\n",
        "    MEG_Signal = scaler.transform(MEG_Signal)\n",
        "    return torch.from_numpy(MEG_Signal), torch.from_numpy(Sound_Signal) , idx_file\n",
        "\n",
        "Dataset = Sound2MEGDataset('/content/drive/MyDrive/sound2meg/mat_files/')  #Can make a vector of sizes in the directory and import it from there\n",
        "training_data, validation_data, test_data = random_split(Dataset, [0.7, 0.2, 0.1], generator=torch.Generator().manual_seed(42))\n",
        "Training_Data_Batches = DataLoader(training_data, batch_size = 128, shuffle = True)\n",
        "#for Sample, Subject in Training_Data:\n",
        "#  print(Sample.shape)\n",
        "Sample, Sound, Subject = Dataset[14462]\n",
        "\n",
        "#Random Batch\n",
        "#batch_size = 3\n",
        "#Samples = torch.zeros(batch_size, 273, 360)\n",
        "#j = 0\n",
        "#Subjects = []\n",
        "#for i in random.sample(range(0, 16446), batch_size):\n",
        "#  S, Sub = Dataset[i]\n",
        "#  Samples[j] = S[:273,:]\n",
        "#  j = j + 1\n",
        "#  Subjects.append(Sub)\n",
        "\n",
        "#print(Samples.shape)\n",
        "#print(Subjects)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spatial_attention import Net as BrainModule\n",
        "Model = BrainModule()\n",
        "X = Model(Samples, Subjects)\n",
        "print(X.shape)"
      ],
      "metadata": {
        "id": "YHiqTEU4sosy",
        "outputId": "ee7b9c33-d54d-493e-a9c9-0e63676d74de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 270, 360, 1])\n",
            "torch.Size([3, 120, 360, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.cumsum(np.array(loadmat('/content/drive/MyDrive/file_sizes.mat')['file_sizes'][0])))"
      ],
      "metadata": {
        "id": "gvlL8kzsWdSN",
        "outputId": "eec1bad5-b2cc-41d5-faff-be7860fbd474",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "169\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sizes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u13kWA-lHpUs",
        "outputId": "dc619ecc-b511-46c4-d0d2-8ae3067d3126"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[147, 168, 171, 166, 167, 178, 170, 152, 180, 99, 165, 169, 170, 169, 170, 171, 164, 174, 160, 174, 183, 171, 178, 162, 155, 167, 163, 154, 164, 90, 174, 168, 162, 173, 163, 170, 170, 169, 170, 178, 174, 170, 163, 162, 164, 170, 179, 164, 178, 146, 22, 177, 170, 160, 169, 178, 153, 166, 172, 158, 167, 164, 105, 0, 174, 169, 169, 166, 49, 172, 168, 164, 166, 166, 165, 177, 161, 166, 169, 168, 178, 165, 168, 160, 171, 171, 169, 165, 173, 157, 170, 171, 157, 171, 171, 172, 156, 175, 158, 168, 168, 164]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mat_file = loadmat('/content/drive/MyDrive/sound2meg/mat_files/' + filename[66])['data']\n",
        "print(mat_file.shape[2])\n",
        "MEG_Signal = np.float32(mat_file[:273, :, 163])"
      ],
      "metadata": {
        "id": "8_iep_QUXbGY",
        "outputId": "0bb4f070-3731-4ee1-e9fa-f69b7ef85ace",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "49\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-0351fb0a5401>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmat_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/sound2meg/mat_files/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m66\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mMEG_Signal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m273\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m163\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: index 163 is out of bounds for axis 2 with size 49"
          ]
        }
      ]
    }
  ]
}