{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/sccn/sound2meg/blob/main/Dataset_Loading.ipynb",
      "authorship_tag": "ABX9TyPcJU8ZOnjZ2Icc4v0sWGxM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sccn/sound2meg/blob/main/Dataset_Loading.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from os import listdir\n",
        "from scipy.io import loadmat\n",
        "filename = []\n",
        "for mat_file in listdir('/content/drive/MyDrive/sound2meg/mat_files'):\n",
        "  filename.append(mat_file)\n",
        "sizes = []\n",
        "for file in filename:\n",
        "  mat_file = loadmat('/content/drive/MyDrive/sound2meg/mat_files/' + file)  #Was really slow to import every file to check the size, hence not included in the class\n",
        "  Signal = mat_file['data']\n",
        "  sizes.append(Signal.shape[2])"
      ],
      "metadata": {
        "id": "o-uGeSfF4ak0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zzo_rM4Dotk",
        "outputId": "09a01c74-2eae-4cc3-995e-4d8196e082ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 273, 360])\n",
            "[66, 91, 70]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from scipy.io import loadmat\n",
        "from os import listdir\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "import random\n",
        "\n",
        "def Cumulative(lists):\n",
        "    cu_list = []\n",
        "    length = len(lists)\n",
        "    cu_list = [sum(lists[0:x:1]) for x in range(0, length+1)]\n",
        "    return cu_list[1:]\n",
        "\n",
        "class Sound2MEGDataset(Dataset):\n",
        "  def __init__(self, meg_files_path):\n",
        "    #self.wav_files = wav_files\n",
        "    self.meg_files_path = meg_files_path\n",
        "    self.sizes = loadmat('/content/drive/MyDrive/file_sizes.mat')['file_sizes'][0]\n",
        "  def __len__(self):\n",
        "    return sum(self.sizes)\n",
        "  def __getitem__(self, idx):\n",
        "    filename = []\n",
        "    for mat_file in listdir('/content/drive/MyDrive/sound2meg/mat_files'):\n",
        "      filename.append(mat_file)\n",
        "    for i in range(len(self.sizes)):\n",
        "      if Cumulative(self.sizes)[i] > idx:\n",
        "        idx_file = i\n",
        "        break\n",
        "    mat_file = loadmat(self.meg_files_path + filename[idx_file])\n",
        "    if idx_file == 0:\n",
        "      idx_sound = idx\n",
        "    else:\n",
        "      idx_sound = idx - Cumulative(self.sizes)[idx_file - 1]\n",
        "    mat_file = mat_file['data']\n",
        "    MEG_Signal = np.float32(mat_file[:, :, idx_sound])\n",
        "    mean_5 = np.mean(MEG_Signal[:,:60], axis=1)\n",
        "    MEG_Signal = MEG_Signal - mean_5[:,None]\n",
        "    transformer = RobustScaler().fit(MEG_Signal)\n",
        "    MEG_Signal = transformer.transform(MEG_Signal)\n",
        "    return torch.from_numpy(MEG_Signal), idx_file\n",
        "\n",
        "Dataset = Sound2MEGDataset('/content/drive/MyDrive/sound2meg/mat_files/')  #Can make a vector of sizes in the directory and import it from there\n",
        "Training_Data = DataLoader(Dataset, batch_size = 128, shuffle = True)\n",
        "Sample, Subject = Dataset[14462]\n",
        "\n",
        "#Random Batch\n",
        "batch_size = 3\n",
        "Samples = torch.zeros(batch_size, 273, 360)\n",
        "j = 0\n",
        "Subjects = []\n",
        "for i in random.sample(range(0, 16446), batch_size):\n",
        "  S, Sub = Dataset[i]\n",
        "  Samples[j] = S[:273,:]\n",
        "  j = j + 1\n",
        "  Subjects.append(Sub)\n",
        "\n",
        "print(Samples.shape)\n",
        "print(Subjects)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spatial_attention import Net as BrainModule\n",
        "Model = BrainModule()\n",
        "X = Model(Samples, Subjects)\n",
        "print(X.shape)"
      ],
      "metadata": {
        "id": "YHiqTEU4sosy",
        "outputId": "ee7b9c33-d54d-493e-a9c9-0e63676d74de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 270, 360, 1])\n",
            "torch.Size([3, 120, 360, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sizes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u13kWA-lHpUs",
        "outputId": "dc619ecc-b511-46c4-d0d2-8ae3067d3126"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[147, 168, 171, 166, 167, 178, 170, 152, 180, 99, 165, 169, 170, 169, 170, 171, 164, 174, 160, 174, 183, 171, 178, 162, 155, 167, 163, 154, 164, 90, 174, 168, 162, 173, 163, 170, 170, 169, 170, 178, 174, 170, 163, 162, 164, 170, 179, 164, 178, 146, 22, 177, 170, 160, 169, 178, 153, 166, 172, 158, 167, 164, 105, 0, 174, 169, 169, 166, 49, 172, 168, 164, 166, 166, 165, 177, 161, 166, 169, 168, 178, 165, 168, 160, 171, 171, 169, 165, 173, 157, 170, 171, 157, 171, 171, 172, 156, 175, 158, 168, 168, 164]\n"
          ]
        }
      ]
    }
  ]
}